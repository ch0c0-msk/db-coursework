{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Формирование CSV-файлов \n",
    "По данным из Elasticsearch сформировать csv-файлы (с внутренней схемой) таблиц «Пассажир», «Билет», «Поезд» и сохранить их в файловой системе HDFS. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from elasticsearch import Elasticsearch\n",
    "from pyspark.sql.types import *\n",
    "import findspark\n",
    "findspark.init()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "client = Elasticsearch(\"http://localhost:9200\")\n",
    "client.ping()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24/05/05 21:06:06 WARN Utils: Your hostname, timerlan-IdeaPad-Gaming-3-15IMH05 resolves to a loopback address: 127.0.1.1; using 192.168.14.252 instead (on interface enp12s0)\n",
      "24/05/05 21:06:06 WARN Utils: Set SPARK_LOCAL_IP if you need to bind to another address\n",
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n",
      "24/05/05 21:06:06 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n"
     ]
    }
   ],
   "source": [
    "sparkSession = SparkSession.builder.appName(\"csv4\").getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'_index': 'train',\n",
       " '_id': '1',\n",
       " '_score': 1.0,\n",
       " '_source': {'train_number': 856234,\n",
       "  'train_info': 'люкс плацкарт св 2011-01-01T12:34 2011-01-03T22:55',\n",
       "  'departure': 'Галич',\n",
       "  'arrive': 'Кировск (Ленин.)',\n",
       "  'tickets_sold': 3,\n",
       "  'tickets_remain': 225}}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "search_query = {\n",
    "    \"match_all\": {}\n",
    "}\n",
    "trains = client.search(index=\"train\", query=search_query, size=100)\n",
    "trains = trains['hits']['hits']\n",
    "trains[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'_index': 'ticket',\n",
       " '_id': '1',\n",
       " '_score': 1.0,\n",
       " '_source': {'user_id': 'd54eb390-46b3-47ff-aeaa-96879e3fbb92',\n",
       "  'personal': 'Галина Валентиновна Николаева',\n",
       "  'date_purchase': '2015-05-25T19:47:14',\n",
       "  'price': 15444.95,\n",
       "  'train_id': 2}}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tickets = client.search(index=\"ticket\", query=search_query, size=100)\n",
    "tickets = tickets['hits']['hits']\n",
    "tickets[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "TrainSchema = StructType([\n",
    "    StructField(\"train_id\", IntegerType(), False),\n",
    "    StructField(\"train_number\", IntegerType(), False),\n",
    "    StructField(\"train_info\", StringType(), False),\n",
    "    StructField(\"departure\", StringType(), False),\n",
    "    StructField(\"arrive\", StringType(), False),\n",
    "    StructField(\"tickets_sold\", IntegerType(), False),\n",
    "    StructField(\"tickets_remain\", IntegerType(), False),\n",
    "])\n",
    "\n",
    "TicketSchema = StructType([\n",
    "    StructField(\"ticket_id\", IntegerType(), False),\n",
    "    StructField(\"user_id\", StringType(), False),\n",
    "    StructField(\"train_id\", IntegerType(), False),\n",
    "    StructField(\"date_purchase_str\", StringType(), False),\n",
    "    StructField(\"price\", FloatType(), False),\n",
    "])\n",
    "\n",
    "PassengerSchema = StructType([\n",
    "    StructField(\"user_id\", StringType(), False),\n",
    "    StructField(\"personal\", StringType(), False),\n",
    "])\n",
    "\n",
    "TrainTab = []\n",
    "TicketTab = []\n",
    "PassengerTab = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+------------+--------------------+----------+----------------+------------+--------------+\n",
      "|train_id|train_number|          train_info| departure|          arrive|tickets_sold|tickets_remain|\n",
      "+--------+------------+--------------------+----------+----------------+------------+--------------+\n",
      "|       1|      856234|люкс плацкарт св ...|     Галич|Кировск (Ленин.)|           3|           225|\n",
      "|       2|      305824|плацкарт купе 201...| Калачинск|      Белокуриха|           5|           937|\n",
      "|       3|      646593|купе плацкарт св ...|  Объячево|          Терней|           1|           467|\n",
      "|       4|      805760|св люкс купе плац...|   Чусовой|          Котлас|           2|           614|\n",
      "|       5|      230075|купе св 2019-10-2...|Лабытнанги|          Брянск|           1|           673|\n",
      "+--------+------------+--------------------+----------+----------------+------------+--------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for train in trains:\n",
    "    TrainTab.append((\n",
    "        int(train['_id']),\n",
    "        train['_source']['train_number'],\n",
    "        train['_source']['train_info'],\n",
    "        train['_source']['departure'],\n",
    "        train['_source']['arrive'],\n",
    "        train['_source']['tickets_sold'],\n",
    "        train['_source']['tickets_remain'],\n",
    "    ))\n",
    "TrainDF = sparkSession.createDataFrame(TrainTab, TrainSchema)\n",
    "TrainDF.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import to_timestamp\n",
    "from pyspark.sql.functions import col"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- ticket_id: integer (nullable = false)\n",
      " |-- user_id: string (nullable = false)\n",
      " |-- train_id: integer (nullable = false)\n",
      " |-- price: float (nullable = false)\n",
      " |-- date_purchase: timestamp (nullable = true)\n",
      "\n",
      "+---------+--------------------+--------+--------+-------------------+\n",
      "|ticket_id|             user_id|train_id|   price|      date_purchase|\n",
      "+---------+--------------------+--------+--------+-------------------+\n",
      "|        1|d54eb390-46b3-47f...|       2|15444.95|2015-05-25 19:47:14|\n",
      "|        2|7eb10bc3-88f8-49b...|      20| 3172.69|2011-11-16 15:12:41|\n",
      "|        3|3e01f5b5-bfe9-4f2...|       5|11806.73|2019-10-18 11:55:25|\n",
      "|        4|ed8df23b-0432-4fe...|       2| 1047.43|2015-06-16 18:47:37|\n",
      "|        5|ed8df23b-0432-4fe...|       2| 2063.12|2015-06-16 18:47:37|\n",
      "+---------+--------------------+--------+--------+-------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "userSet = set()\n",
    "for ticket in tickets:\n",
    "    TicketTab.append((\n",
    "        int(ticket['_id']),\n",
    "        ticket['_source']['user_id'],\n",
    "        ticket['_source']['train_id'],\n",
    "        ticket['_source']['date_purchase'],\n",
    "        ticket['_source']['price'],\n",
    "    ))\n",
    "    if ticket['_source']['user_id'] not in userSet:\n",
    "        PassengerTab.append((\n",
    "            ticket['_source']['user_id'],\n",
    "            ticket['_source']['personal'],\n",
    "        ))\n",
    "        userSet.add(ticket['_source']['user_id'])\n",
    "TicketDF = sparkSession.createDataFrame(TicketTab, TicketSchema)\n",
    "# Преобразуем строку со временем к типу Timestamp\n",
    "TicketDF = TicketDF.withColumn(\"date_purchase\", to_timestamp(\"date_purchase_str\"))\n",
    "TicketDF = TicketDF.drop(\"date_purchase_str\")\n",
    "TicketDF.printSchema()\n",
    "TicketDF.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+--------------------+\n",
      "|             user_id|            personal|\n",
      "+--------------------+--------------------+\n",
      "|d54eb390-46b3-47f...|Галина Валентинов...|\n",
      "|7eb10bc3-88f8-49b...|Белозерова Фёкла ...|\n",
      "|3e01f5b5-bfe9-4f2...|Милий Анисимович ...|\n",
      "|ed8df23b-0432-4fe...|Феоктист Трофимов...|\n",
      "|a94a30eb-a111-421...|Никонова Светлана...|\n",
      "+--------------------+--------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "PassengerDF = sparkSession.createDataFrame(PassengerTab, PassengerSchema)\n",
    "PassengerDF.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from hdfs import InsecureClient"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "client = InsecureClient('http://localhost:9000', user='hduser')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "TrainDF.write.csv(path='hdfs://localhost:9000/db-cw/trains.csv', mode='overwrite', header=True)\n",
    "TicketDF.write.csv(path='hdfs://localhost:9000/db-cw/tickets.csv',mode='overwrite', header=True)\n",
    "PassengerDF.write.csv(path='hdfs://localhost:9000/db-cw/passengers.csv',mode='overwrite', header=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sparkSession.stop()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
